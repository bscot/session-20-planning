{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Unabashedly following Jake van der Plas' excellent overview paper:\n",
    "https://iopscience.iop.org/article/10.3847/1538-4365/aab766\n",
    "\n",
    "Lecture 1 Outline:\n",
    "\n",
    "0. Motivation: what is real data like? nonuniform, different sized error bars.\n",
    "   Why LS? It's the most common, and its generally fast. Major classes of periodicity \n",
    "   detection: phase folding, fourier-based, least-squares model-fitting \n",
    "1a. review: PSD\n",
    "1b. review: convolution thm\n",
    "2. Effect of (uniform) sampling (3.2, fig 7)\n",
    "3. Effect of nonuniform sampling (4, figs 9 & 10)\n",
    "4. Effect of semistructured observing windows (4.2, figs 14 & 15)\n",
    "5. Definitions: beating, aliasing, window function\n",
    "\n",
    "Problem ideas:\n",
    "- given a window function and a true signal, draw the LS periodogram\n",
    "- identify beat frequencies and alias frequencies in LS of real data\n",
    "- decide a follow-up strategy based on a window function & a LS periodogram\n",
    "- (more)\n",
    "\n",
    "Lecture 2 Outline:\n",
    "\n",
    "1. How LS relates to classical periodogram relates to PSD (they are estimators of PSD)\n",
    "2. Sketch derivations of LS: smart choice of coefficients (Scargle) + least squares (Lomb)\n",
    "3. Some useful extensions: uncertainties (6.1), floating mean (6.2), higher-order modes (6.3)\n",
    "4. Computing the window function & the CLEAN algorithm\n",
    "5. FAPS and eFAPS\n",
    "6. When the LS periodogram fails: ex: P/2 being isolated in rotation curve. \n",
    "7. When the LS periodogram fails: correlated noise\n",
    "\n",
    "Problem ideas:\n",
    "- compute the actual periodogram and compare it to the LS periodogram\n",
    "- use astropy periodogram, investigate normalization schemes\n",
    "- numerically compute window function, eFAP, and LS (incorporating/not \n",
    "  uncertainties & floating mean & higher-order modes)\n",
    "- (more)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Time Series: Lomb Scargle Periodograms I\n",
    "\n",
    "Sarah Blunt, CIERA/Northwestern\n",
    "Presented at LSST Discovery Alliance Data Science Fellowship Program Session 20: Time Series\n",
    "\n",
    "TODO: adequately cite van der Plas paper in a way that communicates I've used a lot of ideas and code from his paper. \n",
    "\n",
    "#### Goals for this Lesson:\n",
    "TODO: fill in\n",
    "\n",
    "### I: Motivation\n",
    "(5 mins)\n",
    "\n",
    "Real data are messy. Let's take a look at an example of a real dataset we might want to analyze and identify some problems we might run into constucting a power spectrum.\n",
    "\n",
    "![data-example](data-and-images/vanderPlas-fig1.jpg)\n",
    "\n",
    "What are some problems you notice?\n",
    "- Discrete samples (i.e. not continuous)\n",
    "- Non-uniform sampling\n",
    "- Error bars exist\n",
    "- The error bars are different sizes\n",
    "- There are big gaps in the data\n",
    "- The gaps themselves are somewhat periodic (day/night, and also when the object is visible in the sky)\n",
    "\n",
    "The Lomb-Scargle (LS) periodogram provides a framework for analyzing datasets like this one. However, it's not a perfect tool! The more you understand about how it works, the less likely you will be to misinterpret a LS periodogram. \n",
    "\n",
    "Why are we choosing to focus on the Lomb-Scargle periodogram? There are many, many other methods for detecting periodicity in \"real\" data, which broadly fall into the following categories:\n",
    "- Fourier methods, which are derived from the Fourier transform\n",
    "- Phase-folding methods\n",
    "- Least-squares methods, and\n",
    "- Bayesian methods\n",
    "\n",
    "These are not really separate categories; for example, one can construct a probability function using a phase-folding or least-squares method, then incorporate it into a Bayesian analysis. There are two main reasons that we are devoting so much time to the LS periodogram:\n",
    "\n",
    "Reason #1: It's super popular! You are very likely to encounter the LS periogoram in time-series analysis, so it's important to have a solid understanding.\n",
    "\n",
    "Reason #2: It is related to all four \"classes\" of methods above. It can be derived from Fourier theory (which we will show), and can also be viewed as a least-squares method (which we will also show). We won't discuss this, but it can also be derived from Bayesian probability theory and is closely related to phase-folding techniques. Therefore, gaining intuition about the LS periodogram will help you understand many of these methods, and give you a baseline for understanding other techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II: Brief Review of the Continuous Fourier Transform\n",
    "(10 mins)\n",
    "\n",
    "We will derive the LS periodogram from Fourier analysis, so let's briefly restate some necessary background.\n",
    "\n",
    "#### The Power Spectral Density (PSD)\n",
    "\n",
    "The Fourier transform of a periodic cosine function is:\n",
    "\n",
    "$$\n",
    "\\mathcal{F}\\left\\{\\cos \\left(2 \\pi f_0 t\\right)\\right\\}=\\frac{1}{2}\\left[\\delta\\left(f-f_0\\right)+\\delta\\left(f+f_0\\right)\\right]\n",
    "$$\n",
    "\n",
    "In words, the Fourier transform of a periodic function is the sum of two delta functions: one centered at $-f_0$ and one at $+f_0$. The Fourier transform of a periodic sine function, on the other hand, is:\n",
    "\n",
    "$$\n",
    "\\mathcal{F}\\left\\{\\sin \\left(2 \\pi f_0 t\\right)\\right\\}=\\frac{1}{2i}\\left[\\delta\\left(f-f_0\\right)-\\delta\\left(f+f_0\\right)\\right],\n",
    "$$\n",
    "\n",
    "which is actually just $\\mathcal{F}\\left\\{\\cos \\left(2 \\pi f_0 t\\right)\\right\\}$ multiplied by $e^{-2\\pi i f (\\pi/2)}$. Notice that $\\mathcal{F}\\left\\{\\cos \\left(2 \\pi f_0 t\\right)\\right\\}$ is purely real, and $\\mathcal{F}\\left\\{\\sin \\left(2 \\pi f_0 t\\right)\\right\\}$ is purely imaginary. \n",
    "\n",
    "This motivates the definition of the power spectral density (PSD), which is the **squared magnitude of the Fourier transform**:\n",
    "\n",
    "$$\n",
    "\\mathcal{P}_g \\equiv|\\mathcal{F}\\{g\\}|^2\n",
    "$$\n",
    "\n",
    "While the Fourier transform is a complex number (part real and part imaginary), the PSD is a *real, positive number*. It retains useful properties of the Fourier transform, while being insensitive to time shifts. In other words, while $\\mathcal{F}\\left\\{\\cos \\left(2 \\pi f_0 t\\right)\\right\\}$ and $\\mathcal{F}\\left\\{\\sin \\left(2 \\pi f_0 t\\right)\\right\\}$ have different Fourier transforms, they have the same PSD. This allows you to use the PSD to identify the frequencies making up a signal without worrying about the time-shift.\n",
    "\n",
    "### The Convolution Theorem\n",
    "As Bryan discussed, **convolution** in the time domain is the same as a pointwise product in the frequency domain (this is called the \"convolution theorem\"). Convolution is a mathematical operation (like addition or multiplication) that operates on two functions: it acts to \"slide\" one past the other. Understanding convolution (and the Fourier equivalence) will be immensely helpful in understanding what sampling does to a signal, so let's look at some visual representations of convolution and the convolution theorem.\n",
    "\n",
    "Here's the mathematical definition of the convolution of a function $f$ with a function $g$:\n",
    "\n",
    "$[f * g](t) \\equiv \\int_{-\\infty}^{\\infty} f(\\tau) g(t-\\tau) d \\tau$\n",
    "\n",
    "And here is the convolution theorem:\n",
    "\n",
    "$\\mathcal{F}\\{f * g\\}=\\mathcal{F}\\{f\\} \\cdot \\mathcal{F}\\{g\\}$\n",
    "\n",
    "Here's a visualization of what the convolution operation looks like:\n",
    "\n",
    "![data-example](data-and-images/vanderPlas-fig4.jpg)\n",
    "\n",
    "And here's an example of what the convolution theorem looks like. On the left, the black and grey curves represent the real and imaginary parts of the Fourier transforms (respectively).\n",
    "\n",
    "![data-example](data-and-images/vanderPlas-fig5.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problems:\n",
    "\n",
    "1. Derive the Fourier transform of a sinusoidal function with a time shift. Compute its PSD, and show that it does not depend on the phase shift. This is a general result; the PSD of a time-shifted function will not affect the PSD. Write a sentence about why this is important for time series analysis.\n",
    "\n",
    "TODO: make this question statement more precise.\n",
    "\n",
    "Hint: Write out the Fourier transform of the time-shifted sinusoid, then make the substitution $t_0$ = $t$ + $\\tau$\n",
    "\n",
    "2. In Python, plot a random function between 0 and 1. How would your function look when convolved with a top hat function? How about a Gaussian? What's the difference between the two? Without coding up the answer, draw what you expect. Next, check your work by coding and plotting the convolution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
